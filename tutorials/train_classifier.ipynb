{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a classifier using model2vec\n",
    "\n",
    "Model2Vec supports built-in classifier training with an easy, scikit-learn-based syntax. Just give the model your data in `.fit`, and you'll have a trained model!\n",
    "\n",
    "How it works:\n",
    "* We load a base `StaticModel` using as a torch module. By default we use [potion-base-8m](https://huggingface.co/minishlab/potion-base-8M).\n",
    "* We add a one-layer MLP with 512 hidden units and `ReLU` activation as a head.\n",
    "* We train the model using cross-entropy, using [`pytorch-lightning`](https://lightning.ai/docs/pytorch/stable/) as a training framework.\n",
    "\n",
    "After training, you can export the model using regular torch tools, such as `torch.save` and `torch.load`, or you can export the model to a `scikit-learn` pipeline. The latter option leads to a really small footprint during inference, as there is no longer a need to use `torch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Install the necessary libraries\n",
    "!uv pip install \"model2vec[train,inference]\"\n",
    "!uv pip install \"datasets\"\n",
    "!uv pip install \"scikit-learn\"\n",
    "\n",
    "# Import the necessary libraries\n",
    "from model2vec.train import StaticModelForClassification\n",
    "from model2vec.inference import StaticModelPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate how to train a model, we'll be using the `subjectivity` dataset, which contains short utterances and whether they are subjective or objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"setfit/20_newsgroups\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first five training samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 5 training samples:\n",
    "for record in dataset[\"train\"].to_list()[:5]:\n",
    "    print(f\"TEXT: {record['text']} LABEL: {record['label_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the staticmodel\n",
    "model = StaticModelForClassification.from_pretrained()\n",
    "# Optional arguments:\n",
    "# model_name: the name of the base model (defaults to potion-base-8m)\n",
    "# n_layers: the number of layers in the MLP (defaults to 1)\n",
    "# hidden_dim: the number of hidden units (defaults to 512)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train the model on a subset of examples. We pick the first 1000 examples to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Fit the model on the first 1000 records\n",
    "subset = dataset[\"train\"].select(range(1000))\n",
    "s = time.time()\n",
    "model = model.fit(subset[\"text\"], subset[\"label_text\"])\n",
    "print(f\"training took {time.time() - s} seconds\")\n",
    "# Fit takes many many arguments, check them out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have trained a classifier in five seconds. Nice!\n",
    "\n",
    "Let's take a look at how good it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = model.predict(dataset[\"test\"][\"text\"])\n",
    "\n",
    "print(classification_report(dataset[\"test\"][\"label_text\"], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model scores 0.55 accuracy. But what does this mean? Let's compare it to a `tf-idf` pipeline from `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "sklearn_pipeline = make_pipeline(TfidfVectorizer(), LogisticRegression())\n",
    "sklearn_pipeline.fit(subset[\"text\"], subset[\"label_text\"])\n",
    "predictions = sklearn_pipeline.predict(dataset[\"test\"][\"text\"])\n",
    "\n",
    "print(classification_report(dataset[\"test\"][\"label_text\"], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good! We outperform the tf-idf pipeline by a wide margin.\n",
    "\n",
    "We can now export the model to scikit-learn, and push it to the hub. But first, let's verify whether the predictions of this model and the original model match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = model.to_pipeline()\n",
    "\n",
    "predictions = pipeline.predict(dataset[\"test\"][\"text\"])\n",
    "\n",
    "print(classification_report(dataset[\"test\"][\"label_text\"], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so let's save the model locally, or push it to the hub!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.save_pretrained(\"my_cool_model\")\n",
    "# Fill in your own org\n",
    "# pipeline.push_to_hub(\"my_org/my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This saves a model to a local folder. The model can then be loaded as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = StaticModelPipeline.from_pretrained(\"my_cool_model\")\n",
    "# Or from the hub\n",
    "# model = StaticModelPipeline.from_pretrained(\"my_org/my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One reason to work like this is that the `StaticModelPipeline` does not require torch to be installed at all, leading to really fast cold start predictions, smaller images, and a lot less hassle overall.\n",
    "\n",
    "And that's it! Super fast, super small, super good classifiers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
